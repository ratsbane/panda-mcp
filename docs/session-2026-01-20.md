# Session Log: January 20, 2026

## Summary
Extended session establishing Franka Panda robot control via FCI, camera integration, and building helper utilities for manipulation tasks.

## Key Accomplishments

### 1. FCI Connectivity
- Fixed robot IP configuration (192.168.0.253)
- Set up direct ethernet connection between Pi and robot to achieve <1ms latency
- Installed RT kernel (`linux-image-rpi-v8-rt`) for real-time control
- Movement success rate improved from ~50% to ~80-90%

### 2. Network Configuration
- Created NetworkManager connection "franka-direct" for direct Pi-to-robot link
- Pi IP: 192.168.0.2/24 (shared mode with DHCP)
- Robot received IP: 192.168.0.253 via DHCP

### 3. Camera Integration
- USB camera ("GENERAL WEBCAM") at /dev/video0
- Successfully closed perception-action loop
- Can capture frames and use them to guide arm movements

### 4. Audio/TTS Setup
- Installed espeak-ng and piper TTS
- Downloaded piper voice model (en_US-lessac-medium.onnx)
- Speaker hardware arriving tomorrow

### 5. Helper Utilities Created
- `common/vision.py` - Object detection (color-based, contour-based)
- `common/calibration.py` - Pixel-to-robot coordinate transforms
- `common/manipulation.py` - High-level pick/place planning
- `common/scene_interpreter.py` - Scene analysis and natural language descriptions
- `common/scene_viewer.py` - Interactive viewer with live detection overlays

### 6. MCP Server Updates
- Added `describe_scene` tool to camera-mcp server
- Added `capture_raw()` method to camera controller
- Configured MCP servers in Claude Code settings

### 7. Pick and Place Experiments
- Successfully picked up a stuffed lion and placed it in a basket
- Attempted elephant pickup with mixed success
- Established coordinate convention: +X=forward, +Y=left, +Z=up
- Concluded: 3D vision (depth camera) needed for accurate manipulation

## Files Modified
- `/home/doug/panda-mcp/franka_mcp/controller.py` - IP fix, recover() method
- `/home/doug/panda-mcp/common/safety.py` - Expanded workspace limits
- `/home/doug/panda-mcp/camera_mcp/controller.py` - Added capture_raw()
- `/home/doug/panda-mcp/camera_mcp/server.py` - Added describe_scene tool
- `/home/doug/panda-mcp/common/__init__.py` - Export new modules
- `/boot/firmware/config.txt` - RT kernel configuration
- `~/.claude.json` - MCP server configuration

## Files Created
- `common/vision.py`
- `common/calibration.py`
- `common/manipulation.py`
- `common/scene_interpreter.py`
- `common/scene_viewer.py`

## Hardware Notes
- Robot: Franka Emika Panda at 192.168.0.253
- Camera: USB webcam at /dev/video0 (640x480)
- Compute: Raspberry Pi with RT kernel
- Pending: USB speaker, depth camera (considering PhotoNeo or Intel RealSense D435)

## Next Steps
1. Test USB speaker when it arrives
2. Test wooden blocks for manipulation (easier than soft stuffed animals)
3. Acquire depth camera for accurate Z estimation
4. Complete camera-to-robot calibration
5. Wrist camera mount being 3D printed

## Session ID
`4467799f-c909-4e3e-a77b-ba6f75ee57ba`

Use `claude --resume` to continue this conversation.
